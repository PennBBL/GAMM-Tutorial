---
title: "GAMM Tutorial"
author: "Bart Larsen"
date: "9/29/2019"
output:
  html_document: default
  toc: true
---

# Overview
This tutorial will cover fitting basic GAMM models, significance testing, identifying areas of significant change, and dealing with interactions.

---

```{r setup, include=FALSE}
## Load Libraries
library(ggplot2)
library(grid)
library(cowplot)
library(tidyverse)
library(mgcv)
library(mgcViz)
library(gratia)
library(pbkrtest)
library(broom)
library(scales)
library(kableExtra)
library(RColorBrewer)
font_size <- 16
theme_set(theme_classic(base_family = "sans",base_size = font_size))
line_size <- 1.5
point_size <- 2

```
 

```{r gamm_fx, include= FALSE}
# This function:
# 1. executes the GAMM model,
# 2. sends output to the parametric bootstrap (if requested),
# 3. prints a regression table, and 
# 4. sends the model to the visualizer for plotting.

# Function arguments
# df: your dataframe.
# model_formula: the formula for the model. Can be a string.
# label: if entered, will label plots and tabels with your label (useful if calling for multiple models, etc)
# smooth_var: the variable that you are fitting as a smooth and want to be plotted as a fit line
# int_var: an interaction variable (or a factor variable) that you want to be plotted as separate lines, be tested for significance if desired.
# group_var: Your grouping variable for a mixed model (usually subject ID)
# model_test: if true, will test the last term in your model for significance. Meant for testing if an interaction should remain in them odel. Default is false.
# pbootstrap: if true (and model_test is true), will test the last term in your model using parametric bootstrap permutation test. Default is false.
# p.value: p-value threshold to use for significance testing.

gamm_model <- function(df, model_formula, label=NULL, smooth_var, int_var = NULL,group_var, pbootstrap = F, model_test = T, p.value = .05){
  cat(sprintf("\n\n### Results for %s\n",label))
  if (is.null(label)) {
    label<-model_formula
  }
  label
  
 model_formula <- as.formula(model_formula)

 df$group_var <- df[,group_var]
 
  g1<-gamm(model_formula,
           data=df,
           random = list(group_var =~ 1),
           subset = exclusions == F)
  
  if (model_test == T){
    if (pbootstrap == T) {
      #Send to bootstrap function
      g1$pb<-pboot(g1) 
      #Print a table that shows the bootstrap outcome
      print(g1$pb %>%
        summary() %>%
        .$test %>%
        as.data.frame() %>%
        kable(caption = sprintf("Parametric Bootstrap test for %s",label)) %>%
        kable_styling(full_width = F, position = "left",bootstrap_options = c("striped"))
      )
      
      if (isTRUE(all.equal(g1$pb$bestmod,model_formula))) {
        cat("The initial (more complicated) model is best")
        g <- g1
        
        # Refit the model without with penalized spline for the purpose of plotting
        plot_formula <- as.formula(gsub(", fx = T","",deparse(model_formula)))
        cat(deparse(plot_formula))
        plotg<-g
        plotg <- gamm(plot_formula,
                      data = df,
                      random = list(group_var =~1),
                      subset = exclusions == F)
      } else {
        cat("The simpler model is best")
        cat("   refitting  ")
        g <-gamm(as.formula(g1$pb$bestmod),
                 data=df,
                 random = list(group_var =~ 1),
                 subset = exclusions == F)
        
        # Refit the model with penalized spline for the purpose of plotting
        plot_formula <- as.formula(gsub("ti\\(",'te\\(',deparse(g$gam$formula)) %>% gsub(", fx = T", "", .))
        plotg<-g
        plotg <-gamm(plot_formula,
                 data=df,
                 random = list(group_var =~ 1),
                 subset = exclusions == F)
      }
    } else {
      if (!is.null(int_var)) {
        # We are not bootstrapping, but there is an interaction variable
        s<-summary(g1$gam)
        if (s$s.table[grep(x=rownames(s$s.table),pattern = int_var),"p-value"] <.05/4)  {
          #Checked if interaction is sig, if so keep in the model
          g <- g1
          plot_formula <- as.formula(gsub(", fx = T", "", deparse(model_formula)))
          plotg <- g
        } else {
          #Interaction is not sig, remove from the model
          cat("The simpler model is best")
          thisResp <- as.character(g1$gam$terms[[2]])
          theseVars <- attr(terms(model_formula),"term.labels")
          new_formula <- reformulate(theseVars[0:(length(theseVars)-1)],response = thisResp)
          
          g <-gamm(as.formula(new_formula),
                   data=df,
                   random = list(group_var =~ 1),
                   subset = exclusions == F)
          plot_formula <- as.formula(gsub("ti\\(",'te\\(',deparse(g$gam$formula)) %>% gsub(", fx = T", "", .))
          plotg<-gamm(as.formula(plot_formula),
                   data=df,
                   random = list(group_var =~ 1),
                   subset = exclusions == F)
      }
      } else {
        #There is no interaction term, just plot.
        g <- g1
          plot_formula <- as.formula(gsub(", fx = T", "", deparse(model_formula)))
          plotg <-gamm(as.formula(plot_formula),
                   data=df,
                   random = list(group_var =~ 1),
                   subset = exclusions == F)
      }
    }
  } else {
    g <- g1
    plotg<-g
  }

  g$gam$data<-df %>%
    filter(exclusions == F)
  
  #Display model results:
  s_tidytable<- tidy(g$gam)
  p_tidytable <- tidy(g$gam,parametric = T)
  snames = names(s_tidytable)
  pnames = names(p_tidytable)
  names(s_tidytable)=pnames
  thisBIC <- BIC(g$lme)
  numObs <- g$lme$dims$N
  g$BIC <- thisBIC
  print(concurvity(g$gam)%>%kable(caption = "convurvity")%>%kable_styling(full_width = F,bootstrap_options = "striped",position = "left"))
  stattable <- rbind(p_tidytable,snames,s_tidytable) %>%
    kable(caption = sprintf("Regression table from gamm in %s, BIC = %1.2f, obs = %d",label,thisBIC,numObs)) %>% 
    kable_styling(full_width = F, position = "left")

  print(stattable)
  write.csv(x = rbind(p_tidytable,snames,s_tidytable),file = sprintf("tables/GAMM_table_%s.csv",label),row.names = F)
  cat(sprintf("Regression table from gamm in %s, BIC = %1.2f, obs = %d\n",label,thisBIC,numObs),
      file = sprintf("tables/GAMM_table_%s.txt",label))
  cat(sprintf("Bootstrap p value %1.5f",g1$pb$test["PBtest","p.value"]),
      file = sprintf("tables/GAMM_table_%s.txt",label),
      append = T)

  #Send final model to visualizer:
  if (longPlot == T) {
      g$pl <- longitudinal_plot(g,plabels = label)
    } else{
    if (s_tidytable$p.value[nrow(s_tidytable)]<p.value) {
        g$pl <- visualize_models(plotg,plabels = label, smooth_var = smooth_var, int_var = int_var, group_var = group_var,p.value = p.value)
    }
    }
  #Return result object
  result <- g
  return(result)
}
```

```{r pbootstrap_function, include=FALSE}
## Parametric bootstrap of likelihood ratio test for nested models
## Takes your gamm model object as an input. If you are using `gam` this will have to be tweaked a little.
## Right now, this requires your term of interested to be the LAST term in the model.
pboot <- function(modelobj){
  numsims <- 1000 #This is the number of bootstrap simulations. This # should be higher in practice, probably something like 10,000

  df <- modelobj$gam$model #Get a data frame of all data used in the model (if using gam, this is modelobj$model)
  group_var_name <- names(modelobj$lme$coefficients$random) # the name of the random effects variable
  thisResp <- as.character(modelobj$gam$terms[[2]])
  f1 <- modelobj$gam$formula #Get the formula (if using gam, this is modelobj$formula)
  theseVars <- attr(terms(f1),"term.labels") #Get the terms
  f2 <- reformulate(theseVars[0:(length(theseVars)-1)],response = thisResp) #Drop the last term from the formula. This is the simpler model now.
  
  # The bootstrap function takes an lme object, so we fit the models using gam to get the design matrix, and stick that matrix into lmer
  #Fit
  g1 <- gam(f1,data = df)
  g2 <- gam(f2,data = df)

  #Get the matrices
  mat1 <- model.matrix(g1)
  mat2 <- model.matrix(g2)

  #Tack on the response variable and grouping variable.
  group_var<- df[,group_var_name]
  y <- df[,thisResp]
  
  # Fit the models with `lmer`
  m1 <- lmer(y ~ -1 + mat1 + (1|group_var))
  m2 <- lmer(y ~ -1 + mat2 + (1|group_var))
  
  # Create the bootstrap distribution
  refdist <- PBrefdist(m1, m2, nsim=numsims) # note you can parallelize this (look at help for the function)
  pb <- PBmodcomp(m1, m2, ref = refdist) # Compare the models
  int_pval <- pb$test["PBtest","p.value"] # Pull out the p-value from the bootstrap test.
  
  # Now return the best model
  if (int_pval < .05) {
    pb$bestmod <- f1
  } else {
    pb$bestmod <- f2
  }
  return(pb)
}
```

```{r derivative_plot, include=FALSE}
### function to extract derivative, confidence interval, significance, and plot ###
### This works for signle smooth terms and factor-smooth interactions. Does not work for bivariate smooths.
### This part is still under development.
### If you want to plot derivatives for a by-variable factor model, and you want all plots to have the same scaling, see the note below. Right now you will have to manually set the max value (sorry)

get_derivs_and_plot <- function(modobj,smooth_var,low_color=NULL,hi_color=NULL){
  this_font_size = font_size*1.25
  if (is.null(low_color)){low_color = "white"}
  if (is.null(hi_color)){hi_color = "grey20"}
  derv<-derivatives(modobj,term=smooth_var)
  derv<- derv %>%
    mutate(sig = !(0 >lower & 0 < upper))
  derv$sig_deriv = derv$derivative*derv$sig
  cat(sprintf("\nSig change: %1.2f - %1.2f\n",min(derv$data[derv$sig==T]),max(derv$data[derv$sig==T])))
  d1<- ggplot(data=derv) + geom_tile(aes(x = data, y = .5, fill = sig_deriv))
  
  # Set the gradient colors
  if (min(derv$derivative)>0) {
    d1 <- d1 + scale_fill_gradient(low = low_color, high = hi_color,limits = c(0,max(derv$derivative)))
    # If you want all plots to have the same scaling, this code can be used instead-- This is desirable if you have a factor-smooth model.
    ## max_val = .5
    ## scale_fill_gradient(low = low_color,high = hi_color,limits = c(0,max_val),oob = squish)
  } else if (min(derv$derivative)<0 & max(derv$derivative)<0) {
    d1 <- d1 + scale_fill_gradient(low = hi_color, high = low_color,limits = c(min(derv$derivative),0))
  }else {
    d1 <- d1 +
      scale_fill_gradient2(low = "steelblue", midpoint = 0, mid = "white",
                           high = "firebrick",limits = c(min(derv$derivative),max(derv$derivative)))
  }
  
  d1 <- d1 + 
    labs(x = smooth_var,fill = sprintf("\u0394%s",smooth_var)) + 
    theme(axis.title.y = element_blank(),
          axis.text.y = element_blank(),
          axis.text.x = element_text(size = this_font_size),
          axis.line = element_blank(),
          axis.ticks.y = element_blank(),
          text = element_text(size=this_font_size),
          legend.text = element_text(size = this_font_size),
          axis.title = element_text(size = this_font_size),
          legend.key.width = unit(1,"cm"),
          legend.position = "right",
          plot.margin = unit(c(0, 0, 0, 0), "cm"))+
    guides(fill = guide_colorbar(reverse = F,direction = "horizontal",title.position = "top")) +
    geom_rect(aes(ymin=0,ymax=1,xmin=min(data),xmax=max(data)),color="black",fill="white",alpha = 0)
  return(d1)
}

```


```{r visual func, include=FALSE}
# Func to visualize model outputs
visualize_model <- function(modobj,smooth_var, int_var ,group_var, plabels = NULL,check_diagnostics = F,derivative_plot = F){
  this_font_size = font_size*1.25
  if (any(class(modobj)=="gam")) {
    model <- modobj
  } else if (class(modobj$gam)=="gam") {
    model <- modobj$gam
  } else {
    stop("Can't find a gam object to plot")
  }
  s<-summary(model)

  ## Generate custom line plot
  np <- 10000 #number of predicted values
  df = model$model

  theseVars <- attr(model$terms,"term.labels")
  varClasses <- attr(model$terms,"dataClasses")
  thisResp <- as.character(model$terms[[2]])

  if (!is.null(int_var)) {
    # We will produce and interaction plot
    if (!any(grepl(x=as.character(model$formula),pattern = int_var))) {
      warning("int_var not recognized in model formula!")
      return()
    }
    switch (varClasses[int_var],
      "numeric" = {
        q <- quantile(df[,int_var],probs = c(.05,.95)) #pick 10% and 90% to plot
        bigq <- q[[2]]
        smallq <- q[[1]]
        values <- c(bigq,smallq)
        labs <- c(sprintf("high (%1.2f)",bigq),sprintf("low (%1.2f)",smallq))

        q <-quantile(rescale(df[,int_var],c(0,1)),probs = c(0,.5,1))
        limit_values <- c(q[[1]],q[[length(q)]])
        midpoint_val <- unname(q[[2]])
        cbar_vals <- unname(q)
        
        theseLabs = rep(values,each = np)
        grad_fill = T
      },
      "factor" = {
        labs <- levels(df[,int_var])
        values <- levels(df[,int_var])
        theseLabs = rep(values,each = np)
        grad_fill = F
      },
      "ordered" = {
        labs <- levels(df[,int_var])
        values <- levels(df[,int_var])
        theseLabs = ordered(rep(values,each = np),levels = values)
        grad_fill = F
      }
    )

    labPred <- data.frame(init = rep(0,np*length(labs)))
    labPred[,int_var] = theseLabs
    labPred$lab = rep(labs,each = np)
    labPred <- labPred[,names(labPred) !="init"]
    thisPred <- data.frame(init = rep(0,np))
    
    for (v in c(1:length(theseVars))) {
      thisVar <- theseVars[[v]]
      thisClass <- varClasses[thisVar]
      if (thisVar == smooth_var) {
        thisPred[,smooth_var] = seq(min(df[,smooth_var],na.rm = T),max(df[,smooth_var],na.rm = T), length.out = np)
      } else if (v == int_var) {
        next
      } else {
        switch (thisClass,
            "numeric" = {thisPred[,thisVar] = median(df[,thisVar])},
            "factor" = {thisPred[,thisVar] = levels(df[,thisVar])[[1]]},
            "ordered" = {thisPred[,thisVar] = levels(df[,thisVar])[[1]]}
              )
      }
    }

    thisPred <- thisPred %>% select(-init)
    thisPred <- do.call("rbind", replicate(length(labs), thisPred, simplify = FALSE))

    pred <- cbind(labPred,thisPred)
    p<-data.frame(predict(model,pred,se.fit = T))
    pred <- cbind(pred,p)
    pred$selo <- pred$fit - 2*pred$se.fit
    pred$sehi <- pred$fit + 2*pred$se.fit
    pred[,group_var] = NA #these columns have to exist in the dataframe for plotting
    pred[,thisResp] = 1 #these columns have to exist in the dataframe for plotting

    low_color = "#91bfdb"
    high_color = "#fc8d59"
    high_line = "#f46d43"
    low_line = "#4575b4"
    
    if (grad_fill == T) {
      p1 <- ggplot(data = df, aes_string(x = smooth_var,y = thisResp, color = int_var)) +
      geom_point(alpha = 0.55,stroke = 0, size = point_size) + geom_line(aes_string(group = group_var),alpha = .5) +
      scale_color_gradientn(colors = c(low_color,high_color), values = cbar_vals,name = "") +
      geom_ribbon(data = pred,aes_string(x = smooth_var , ymin = "selo",ymax = "sehi", fill = "lab"),alpha = .18, linetype = 0) +
      scale_fill_manual(values = c(high_color,low_color)) +
      geom_line(data = pred,aes_string(x = smooth_var, y = "fit",group = "lab"),size = line_size) +
      labs(title = plabels)
    } else {

    p1 <- ggplot(data = df, aes_string(x = smooth_var,y = thisResp, color = int_var)) +
      geom_point(alpha = .35,stroke = 0, size = point_size) + geom_line(aes_string(group = group_var),alpha = .3) +
      scale_color_brewer(type = "qual",palette = "Set1",direction = 1) +
      geom_ribbon(data = pred,aes_string(x = smooth_var , ymin = "selo",ymax = "sehi", fill = int_var),alpha = .5, linetype = 0) +
      scale_fill_brewer(type = "qual",palette = "Set1",direction = 1) +
      geom_line(data = pred,aes_string(x = smooth_var, y = "fit",color = int_var),size = line_size) +
      labs(title = plabels)
    }
  } else {

  # No interaction variable, just produce a single line plot
    thisPred <- data.frame(init = rep(0,np))

    for (v in c(1:length(theseVars))) {
      thisVar <- theseVars[[v]]
      thisClass <- varClasses[thisVar]
      if (thisVar == smooth_var) {
        thisPred[,smooth_var] = seq(min(df[,smooth_var],na.rm = T),max(df[,smooth_var],na.rm = T), length.out = np)
      } else {
        switch (thisClass,
            "numeric" = {thisPred[,thisVar] = median(df[,thisVar])},
            "factor" = {thisPred[,thisVar] = levels(df[,thisVar])[[1]]},
            "ordered" = {thisPred[,thisVar] = levels(df[,thisVar])[[1]]}
              )
      }
    }
    pred <- thisPred %>% select(-init)
    p<-data.frame(predict(model,pred,se.fit = T))
    pred <- cbind(pred,p)
    pred$selo <- pred$fit - 2*pred$se.fit
    pred$sehi <- pred$fit + 2*pred$se.fit
    pred[,group_var] = NA
    pred[,thisResp] = 1

    p1 <- ggplot(data = df, aes_string(x = smooth_var,y = thisResp)) +
      geom_point(alpha = .3,stroke = 0, size = point_size) + geom_line(aes_string(group = group_var),alpha = .3) +
      geom_ribbon(data = pred,aes_string(x = smooth_var , ymin = "selo",ymax = "sehi"),alpha = .5, linetype = 0) +
      geom_line(data = pred,aes_string(x = smooth_var, y = "fit"),size = line_size) +
      labs(title = plabels)
  }

  if (derivative_plot == T) {
    # We will add a bar that shows where the derivative is significant.
    # First make some adjustments to the line plot.
    p1<- p1+theme(text = element_text(size=this_font_size),
                axis.text = element_text(size = this_font_size),
                axis.title.y = element_text(size = this_font_size),
                axis.title.x = element_blank(),
                axis.text.x = element_blank(),
                axis.ticks.x = element_blank(),
                legend.text = element_text(size = this_font_size),
                legend.title = element_text(size = this_font_size),
                axis.title = element_text(size = this_font_size),
                panel.grid.major = element_blank(),
                panel.grid.minor = element_blank(),
                panel.background = element_rect(fill = "transparent",colour = NA),
                plot.background = element_rect(fill = "transparent",colour = NA),
                plot.margin = unit(c(.2, .2, 0, .2), "cm")) #Top, left,Bottom, right
    scatter <- list(p1)
    
    # Now add the plots using the derivative plotting function
    if (any(grepl(x = row.names(s$s.table),pattern =  ":") & grepl(x=row.names(s$s.table),pattern = int_var))) {
      # Factor levels separately if there is an interaction in the model.
      f<-formula(model) # current formula
      fterms <- terms(f)
      fac <- attr(fterms, "factors")
      idx <- which(as.logical(colSums(fac[grep(x=row.names(fac),pattern = int_var),])))
      new_terms <- drop.terms(fterms, dropx = idx, keep.response = TRUE)
      new_formula <- formula(new_terms) # Formula without any interaction terms in the model.
      
      #add derivative gradients for each level of the factor
      num_levels <- length(levels(df[,int_var]))
      level_colors <- suppressWarnings(RColorBrewer::brewer.pal(num_levels,"Set1")) #use the same palette as the line plot
      plotlist = vector(mode = "list",length = num_levels+1) # we will be building a list of plots
      plotlist[1] = scatter # first the scatter plot
      
      for (fcount in 1:num_levels) {
        this_level <- levels(df[,int_var])[fcount]
        df$subset <- df[,int_var] == this_level
        df$group_var <- df[,group_var]
        this_mod <- gamm(formula = new_formula,data = df,subset = subset,random=list(group_var=~1))
        # this_d <- get_derivs_and_plot(modobj = this_mod,smooth_var = smooth_var,low_color = "white",hi_color = level_colors[fcount])
        this_d <- get_derivs_and_plot(modobj = this_mod,smooth_var = smooth_var,low_color = "white",hi_color = level_colors[fcount])
        
        if (fcount != num_levels & fcount != 1){
          # get rid of redundant junk
          this_d$theme$axis.title = element_blank()
          this_d$theme$axis.text.x = element_blank()
          this_d$theme$axis.ticks=element_blank()
          this_d$theme$legend.background=element_blank()
          this_d$theme$legend.box.background = element_blank()
          this_d$theme$legend.key = element_blank()
          this_d$theme$legend.title = element_blank()
          this_d$theme$legend.text = element_blank()
        }
        if (fcount == 1) {
         this_d$theme$axis.title = element_blank()
         this_d$theme$axis.text.x = element_blank()
         this_d$theme$axis.ticks=element_blank()
         this_d$theme$legend.background=element_blank()
         this_d$theme$legend.box.background = element_blank()
         this_d$theme$legend.key = element_blank()
         this_d$theme$legend.text = element_blank()
        }
        if (fcount == num_levels) {
         this_d$theme$legend.background=element_blank()
         this_d$theme$legend.box.background = element_blank()
         this_d$theme$legend.key = element_blank()
         this_d$theme$legend.title = element_blank()
        }
        this_d$labels$fill=NULL
        plotlist[fcount+1] = list(this_d)
      }
      pg<-plot_grid(rel_heights = c(16*num_levels,rep(num_levels,num_levels-1),3*num_levels),plotlist = plotlist,align = "v",axis = "lr",ncol = 1)
      final_plot <- pg
      print(final_plot)
  } else {
    # No need to split
    d1 <- get_derivs_and_plot(modobj = modobj,smooth_var = smooth_var)
    scatter <- list(p1)
    bar <- list(d1)
    allplots <- c(scatter,bar)
    pg<-plot_grid(rel_heights = c(16,3),plotlist = allplots,align = "v",axis = "lr",ncol = 1)
    final_plot <- pg
    print(final_plot)
  }

  }    else {
    # No derivative plot
    p1<- p1+theme(text = element_text(size=font_size),
                axis.text = element_text(size = font_size),
                legend.text = element_text(size = font_size),
                panel.grid.major = element_blank(), 
                panel.grid.minor = element_blank(),
                panel.background = element_blank(),
                plot.background = element_blank())
    final_plot <- p1
    print(final_plot)
  }
  
  if (check_diagnostics == T) {
    cp <- check(b,
    a.qq = list(method = "tnorm",
                a.cipoly = list(fill = "light blue")),
    a.respoi = list(size = 0.5),
    a.hist = list(bins = 10))
    print(cp)
  }
  return(final_plot)
}
```

---
```{r load data, warning=FALSE, include=T }
# Load the datafile
dataFile <- "r2star_data.csv"
df <- read.csv(dataFile)

```

---

# Fitting a basic GAMM
Fitting a nonlinear age effect. We will look at the development of R2* in the Accumbens as an example.
The model will also include a covariate for sex.
Here is the model formula: `Accumbens_Area ~ sex +s(age, k = 4)`
`s` indicates we will use a spline smooth. The default is a thin plate regression spline (you should have a good reason to change this)
`k` sets a maximum for the amount of knots that can be fit. The max degrees of freedom for the spline is k-1. For development, we don't really expect more than 2 or 3 inflection points, so `k=4` is pretty reasonable.
```{r basic_GAMM}
# Define the model formula
model_formula <- as.formula("Accumbens_Area ~ sex +s(age, k = 4)")
model <- gamm(model_formula,
              random = list(bblid=~1), # We specify a random intercept for subject id (bblid). gamm uses lists for this.
              data = df)
```

## Look at the results
`gamm` model objects have two parts, a `gam` object and an `lme` object. Use the `gam` object for summary, prediction, plotting, etc.  
The thin plate regression spline is a penalized spline that tries to optimize the wiggliness in the fit. The `edf` is representing the effective degrees of freedom after penalization.
```{r GAMM_results}
summary(model$gam) 
```


## Significance of the smooth term
Though fitting the model as we did is nice for optimizing the smoothness of the fit, it may not be ideal when we care about significance testing. This is because the penalized term p-values can be unreliable and sometimes underestimated. When we care about significance testing, we should fit the smooths using unpenalized splines by setting `fx = F`.
```{r smooth_sig, warning=FALSE}
model_formula <- as.formula("Accumbens_Area ~ sex +s(age, k = 4, fx = T)")
model <- gamm(model_formula,
              random = list(bblid=~1),
              data = df)

# Look at the model summary
summary(model$gam) 

# Let's plot the model
final_plot <- visualize_model(modobj = model,smooth_var = "age",int_var=NULL,group_var = "bblid")
# We can adjust the axes limits and labels
final_plot + ylim(10,30) + labs(x="Age (Years)",y = "Accumbens R2* (1/sec)")
```

# Where is my smooth fit significantly changing?
We can answer this question by looking at the derivative of the smooth function, calculating the confidence interval, and identifying where the derivative is significantly non-zero.

Luckily there was a package recently developed by Gavin Simpson that can do this for us!
Package info: https://github.com/gavinsimpson/gratia
Blog post introducing the package: https://www.fromthebottomoftheheap.net/2018/10/23/introducing-gratia/
Interesting blog posts about the method for derivatives: https://www.fromthebottomoftheheap.net/2017/03/21/simultaneous-intervals-for-derivatives-of-smooths/

Let's start with the model from our first example
```{r derivative-model}
model_formula <- as.formula("Accumbens_Area ~ sex +s(age, k = 4, fx = T)")
model <- gamm(model_formula,
              random = list(bblid=~1),
              data = df)
```

Now let's get the derivative.
```{r derivative-calculate, warning=FALSE, fig.height=3,fig.width=4}
# Calculate the derivative
d<-derivatives(model,n=1000)

# Take a look at it using gratia::draw
d_plot <- draw(d)
print(d_plot)

# Identify significant areas
d<- d %>%
  mutate(sig = !(0 >lower & 0 < upper)) #Ages where the CI does not include zero
cat(sprintf("\nSignificant change: %1.2f - %1.2f\n",min(d$data[d$sig==T]),max(d$data[d$sig==T]))) #this only works properly if there is one contiguous area of significant change (sorry)

# Add some ornaments to the plot
d_plot <- ggplot(data = d,aes(x=data,y = derivative,color=sig, ymin=lower,ymax=upper)) + geom_ribbon(fill="black",alpha=.3,color=NA) + geom_line(size=1,show.legend = F) +scale_color_manual(values = c("TRUE" = "firebrick","FALSE" = "black")) + geom_hline(yintercept = 0,linetype=2)

# Let's visualize using our visualizer function

big_plot <- visualize_model(modobj = model,smooth_var = "age",int_var = "sex",group_var = "bblid",plabels = "scatter + derivative", derivative_plot = T)

# Note: Currently the derivative_plot = T is very finicky about the output figure size. It is best to use ggsave to output
ggsave(plot = big_plot,filename = "derivative_fig.png",device = "png",width = 180,height = 120,units = "mm")
knitr::include_graphics("derivative_fig.png")

```

---
# Modeling interactions with GAMMs
We can investigate factor-smooth interactions and continuous interactions.  

## Fitting a factor-smooth interaction
Factor-smooth interactions allow you to test whether the smoothed term varies across levels of a factor.
In this example, we'll fit nonlinear age effect and check for age*sex interaction, `s(age, by = oSex)`.
We will test in the Pallidum because we have an interaction here.

NOTE: If you are interested in whether the smooths DIFFER between levels of the factor, which we usually do when testing for an interaction, the variable types and model specification matter!
The factor must be specified as an ordered factor, and you must include a "main effect" smooth in the model.
This fits a reference smooth at the first level of your factor and models smooths at the other levels as a comparison to the reference.
We will create a variable `oSex` as an ordered factor of sex, and test the model as
`Pallidum ~ oSex +s(age, k = 4, fx = T) + s(age, by = oSex, k = 4, fx = T)`

```{r developmental,eval=T,warning=F,fig.height=7,fig.width=7}
df$oSex <- ordered(df$sex, levels = c("female","male")) # Females will be the reference group

model_formula <- as.formula("Pallidum ~ oSex + s(age, k = 4, fx = T) + s(age, by = oSex, k = 4, fx = T)")
# Note we keep fx = T for reliable p-values.

model <- gamm(model_formula,
              random = list(bblid=~1),
              data = df)

summary(model$gam)
```

It looks like we have a significant interaction here. In order to confirm the p-value for the interaction, we can compare this model to a main effect only model and see if it is a significant improvement. This can be done with a bootstrap likelihood ratio test. Let's make a function to do this:

```{r pbootstrap}
## Parametric bootstrap of likelihood ratio test for nested models
## Takes your gamm model object as an input. If you are using `gam` this will have to be tweaked a little.
## Right now, this requires your term of interested to be the LAST term in the model.
pboot <- function(modelobj){
  numsims <- 1000 #This is the number of bootstrap simulations. This # should be higher in practice, probably something like 10,000

  df <- modelobj$gam$model #Get a data frame of all data used in the model (if using gam, this is modelobj$model)
  group_var_name <- names(modelobj$lme$coefficients$random) # the name of the random effects variable
  thisResp <- as.character(modelobj$gam$terms[[2]])
  f1 <- modelobj$gam$formula #Get the formula (if using gam, this is modelobj$formula)
  theseVars <- attr(terms(f1),"term.labels") #Get the terms
  f2 <- reformulate(theseVars[0:(length(theseVars)-1)],response = thisResp) #Drop the last term from the formula. This is the simpler model now.
  
  # The bootstrap function takes an lme object, so we fit the models using gam to get the design matrix, and stick that matrix into lmer
  #Fit
  g1 <- gam(f1,data = df)
  g2 <- gam(f2,data = df)

  #Get the matrices
  mat1 <- model.matrix(g1)
  mat2 <- model.matrix(g2)

  #Tack on the response variable and grouping variable.
  group_var<- df[,group_var_name]
  y <- df[,thisResp]
  
  # Fit the models with `lmer`
  m1 <- lmer(y ~ -1 + mat1 + (1|group_var))
  m2 <- lmer(y ~ -1 + mat2 + (1|group_var))
  
  # Create the bootstrap distribution
  refdist <- PBrefdist(m1, m2, nsim=numsims) # note you can parallelize this (look at help for the function)
  pb <- PBmodcomp(m1, m2, ref = refdist) # Compare the models
  int_pval <- pb$test["PBtest","p.value"] # Pull out the p-value from the bootstrap test.
  
  # Now return the best model
  if (int_pval < .05) {
    pb$bestmod <- f1
  } else {
    pb$bestmod <- f2
  }
  return(pb)
}
```

### Now use the function to test the model.
```{r factor-smooth test}
pb <- pboot(model)

#Print a table that shows the bootstrap outcome
pb %>%
  summary() %>%
  .$test %>%
  as.data.frame() %>%
  kable(caption = "Parametric Bootstrap test results") %>%
  kable_styling(full_width = F, position = "left",bootstrap_options = c("striped"))

# The bootstrap p-value confirms that the our interaction term is a significant improvement
# This code will handle keeping the best model.
if (isTRUE(all.equal(pb$bestmod,model_formula))) {
  cat("The initial (more complicated) model is best")
  final_model <- model

} else {
  cat("The simpler model is best")
  cat("   refitting  ")
  final_model <-gamm(as.formula(pb$bestmod),
                     data=df,
                     random = list(bblid =~ 1),
                     subset = exclusions == F)
}

summary(final_model$gam)
```

We can simplify the summary a little bit. This is helpful if you are looping over many models and want to see the results at a glance.
```{r summary_table, results="asis"}
#Display model results:
smooths_tidytable<- tidy(final_model$gam)
parametric_tidytable <- tidy(final_model$gam,parametric = T)
smoothnames = names(smooths_tidytable)
parametricnames = names(parametric_tidytable)
names(smooths_tidytable)=parametricnames
numObs <- final_model$lme$dims$N

stattable <- rbind(parametric_tidytable,smoothnames,smooths_tidytable) %>%
  kable(caption = sprintf("Regression table from gamm. N = %d",numObs)) %>% 
  kable_styling(full_width = F, position = "left")
print(stattable)
```

### Plot the results
```{r plotting final model}
# Send to visualizer function
# int_var is the factor, will be plotted as separate lines
# group_var identifies the variable that links points in the spaghetti plot
# plabel will attach a title to the plot
model_plot <- visualize_model(modobj = final_model,smooth_var = "age",int_var = "oSex",group_var = "bblid",plabels = "Factor-smooth interaction",check_diagnostics = F)

# Adjust some labels and plot limits
model_plot<- model_plot + labs(y = "Pallidum R2* (1/sec)", x = "Age (years)") + ylim(12,30)
print(model_plot)
```

```{r plot_w_derivatives, fig.height=3,fig.width=4}
# We can also get the derivatives
model_plot <- visualize_model(modobj = final_model,smooth_var = "age",int_var = "oSex",group_var = "bblid",plabels = "Factor-smooth interaction",derivative_plot = T)

# Save the plot
ggsave(plot = big_plot,filename = "derivative_fig2.png",device = "png",width = 180,height = 120,units = "mm")
knitr::include_graphics("derivative_fig2.png")
```

## Modeling of continuous*continuous interactions

There are two possible models  
1. Additive (main effects + interaction) bivariate smooth model (fully nonlinear interaction)  
2. varying coefficient model (linear-nonlinear interaction)  

Model selection and significance testing workflow:  
* We select the best model is based on the smallest BIC (or AIC).  
* After the best interaction  model is selected, the significance of the interaction is tested with a parametric bootstrap likelihood ratio test. This test compares the model with the interaction term against a simpler nested model with main effects only.  
* If the interaction model is significantly better, we keep that model. If not, the final model is the simpler model with no interaction.  

### Model 1: 2D smooth with additional main effects and tensor product smooth, `ti`: `ti(age) + ti(Cognition) + ti(age,Cognition)`

From documentation: 
This model specifies a main effects + interaction structure such as:
`y ~ ti(x) + ti(z) + ti(x,z)`  

`ti` is the proper way of specifying an interaction term in the context of included main effect terms:  

"This functional ANOVA decomposition is supported by ti terms, which produce tensor product interactions from which the main effects have been excluded, under the assumption that they will be included separately. For example the ~ ti(x) + ti(z) + ti(x,z) would produce the above main effects + interaction structure. This is much better than attempting the same thing with s or te terms representing the interactions (although mgcv does not forbid it). Technically ti terms are very simple: they simply construct tensor product bases from marginal smooths to which identifiability constraints (usually sum-to-zero) have already been applied: correct nesting is then automatic (as with all interactions in a GLM framework). See Wood (2017, section 5.6.3)."  

NOTE: This model model can onl be fit as a GAMM using `gamm`. This specification is not available with `gamm4`.

### Varying coefficient model (using `by =`)

This will make the fit linear (rather than non-linear smooth) in the `by` variable.
From documentation: 
"When using `by` with a numberic covariate, "the by argument ensures that the smooth function gets multiplied by covariate z"

### Example
```{r continuous interactions, results="asis",warning=F}
# Compare the two interaction models
# Bivariate interaction model
bv_formula <- as.formula("Putamen ~ ti(age, k=4, fx = T) + ti(NAR_Overall_Efficiency, k=4, fx = T) + ti(age,NAR_Overall_Efficiency, k=4, fx = T)")
# Linear varying coefficient interaction
vc_formula <- as.formula("Putamen ~ s(age, k=4, fx = T) + s(age, by = NAR_Overall_Efficiency, k=4, fx = T)")

# Fit each model
bv <- gamm(as.formula(bv_formula),
           random = list(bblid=~1),
           data = df)
vc <- gamm(as.formula(vc_formula),
           random = list(bblid=~1),
           data = df)
# get BIC
bic<-BIC(bv$lme,vc$lme) #Get the BIC from the lme object for gamm
bestmod <- gsub(row.names(bic)[which.min(bic$BIC)],pattern = "$lme",replacement = "", fixed = T) #best is min BIC

switch (bestmod,
  "bv" = {model <- bv},
  "vc" = {model <- vc}
)

model_formula <- model$gam$formula
anova(model$gam)

# Confirm the interaction model is a significant improvement.
pb <- pboot(model)

#Print a table that shows the bootstrap outcome
pb %>%
  summary() %>%
  .$test %>%
  as.data.frame() %>%
  kable(caption = "Parametric Bootstrap test results") %>%
  kable_styling(full_width = F, position = "left",bootstrap_options = c("striped"))

# Plot the outcome
model_plot <- visualize_model(modobj = model,smooth_var = "age",int_var = "NAR_Overall_Efficiency",group_var = "bblid",plabels = "continuous interaction",derivative_plot = F)
model_plot <- model_plot + ylim(10,22) + labs(x="Age (Years)", y = "Putamen R2* (1/sec)")
print(model_plot)

```

### Concurvity
Since the varying coefficient model was the best model, let's confirm we don't have any concurvity issues between the main effect and the interaction.  
We can use the `concurvity` function to assess this. 
From the help documentation,`?concurvity`
> Concurvity occurs when some smooth term in a model could be approximated by one or more of the other smooth terms in the model.  
Concurvity can be viewed as a generalization of co-linearity, and causes similar problems of interpretation. It can also make estimates somewhat unstable.  
Concurvity is a value betwee zero and one, with zero indicating no problem, and 1 indicating lack of indentifiability.


```{r concurvity}
# Check the concurvity of the vc model.
c<-as.data.frame(concurvity(model$gam))
c %>% 
  kable(caption = "Convurvity")%>%
  kable_styling(full_width = F,bootstrap_options = "striped",position = "left")
```

###Other visualization options
There are a number of cool packages out there for visualizing GAM models. One caveat is that they are generally meant for GAM rather than GAMM, and don't have options to add a spaghetti plot. I ended up making my own visualizer function to get spaghetti plots and add derivative information, but these are definitely worth checking out.  

`vis.gam` comes with `mgcv` and can make a few different plots. I like the perspective plot (example below).  

`mgcViz` also makes some pretty plots for all the terms in your model (smooths and parametric terms). I included one example below, but you can check out their vignette for more: https://cran.r-project.org/web/packages/mgcViz/vignettes/mgcviz.html  

`itsadug` is also a cool package that has some extra nifty tools for exploring your model. See the vignette here: https://cran.r-project.org/web/packages/itsadug/vignettes/inspect.html  

`gratia` is a newer package that also has some handy plotting and diagnostic tools. We have used it already here for calculating derivatives and confidence intervals for derivatives. Info can be found here: https://gavinsimpson.github.io/gratia/  
```{r model_vis_options}

# Using vis.gam
# This is set up for gam, not gamm, so we have to change our gam object a bit
model$gam$data <- model$gam$model
vis.gam(model$gam,view = c("age","NAR_Overall_Efficiency"),plot.type = "persp",theta = 45,color = "topo",zlab = "Putamen R2*")

b <- getViz(model$gam)
var_plot <- plot(b,allTerms = T) + 
  l_ciPoly() +
  l_fitRaster() + l_fitContour() + 
  l_points() +  l_ciBar() +
  l_fitPoints(size = 1, col = 2) + l_fitLine() +
  labs(title = "mgcViz plots")
print(var_plot,pages = 1)

```